{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e28c26be",
   "metadata": {},
   "source": [
    "# Submission Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626b814",
   "metadata": {},
   "source": [
    "## Reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff3be5",
   "metadata": {},
   "source": [
    "### Running the QRF Model \n",
    "\n",
    "\n",
    "    The model is based off the paper Srikumar et al., \"A kernel-based quantum random forest for improved classification\", (2022). The code is intended for research purposes and the development of proof of concepts. For questions about the code, please email maiyuren.s@gmail.com for clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5194645",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_random_forest import QuantumRandomForest, set_multiprocessing\n",
    "from split_function import SplitCriterion\n",
    "from data_construction import data_preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372c9d8",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "\n",
    "Here you can load your own dataset. The preprocessing can be left untouched. However, it is important to note that certain embeddings require data of certain dimension. PCA reduction to the required dimension can be achieved by changing the X_dim variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bcf185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "num_classes = 2\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83d3abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New datapoint dimension: 6\n"
     ]
    }
   ],
   "source": [
    "training_set, testing_set = data_preprocessing(X, y, \n",
    "                                               train_prop=0.75,        # Proportion of dataset allocated for training\n",
    "                                               X_dim=6)                # Determine the required dimension of the dataset. None for default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d0744",
   "metadata": {},
   "source": [
    "#### Model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f4309af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 6                                         # Number of qubits for the embedding\n",
    "dt_type = 'qke'                                      # Do not touch\n",
    "ensemble_var = None                                  # Do not touch\n",
    "branch_var = ['eff_anz_pqc_arch', \n",
    "              'iqp_anz_pqc_arch', \n",
    "              'eff_anz_pqc_arch']                    # Type of Anzatz, or as a list for different down the tree - as given \n",
    "num_trees = 3                                        # Number of trees in ensemble \n",
    "split_num = 2                                        # Do not touch\n",
    "pqc_sample_num = 2024                                # Number of circuit samples per kernel estimation\n",
    "num_classes = num_classes                            # Number of classes in dataset\n",
    "max_depth = 4                                        # Maximum depth of the tree\n",
    "num_params_split = n_qubits*(n_qubits +1)            # Number of parameters in the embedding (different for different anzatz), list for different down the tree [2 * n_qubits ** 2 , n_qubits*(n_qubits +1), 2 * n_qubits ** 2]\n",
    "num_rand_gen = 1                                     # Do not touch\n",
    "num_rand_meas_q = n_qubits                           # Do not touch \n",
    "svm_num_train = 5                                    # L, Number of Landmarks\n",
    "svm_c = 10                                           # C term in SVM optimisation, or list down the tree [100, 50, 20]\n",
    "min_samples_split = svm_num_train                    # Minimum number of samples\n",
    "embedding_type = ['as_params_all', \n",
    "                  'as_params_iqp', \n",
    "                  'as_params_all']                   # Type of embedding, or as a list - as given\n",
    "criterion = SplitCriterion.init_info_gain('clas')    # Do not touch\n",
    "device = 'cirq'                                      # Choose a device. Also possible to run on IBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4864d1de",
   "metadata": {},
   "source": [
    "#### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9498c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrf_reproduction = QuantumRandomForest(n_qubits, 'clas', num_trees, criterion, max_depth=max_depth, \n",
    "                          min_samples_split=min_samples_split, tree_split_num=split_num, num_rand_meas_q=num_rand_meas_q,\n",
    "                          ensemble_var=ensemble_var, dt_type=dt_type, num_classes=num_classes, ensemble_vote_type='ave',\n",
    "                          num_params_split=num_params_split, num_rand_gen=num_rand_gen, pqc_sample_num=pqc_sample_num,\n",
    "                          embed=embedding_type, branch_var=branch_var, svm_num_train=svm_num_train, svm_c=svm_c, \n",
    "                          nystrom_approx=True, device=device, cholesky=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1911f4dc",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b4f86ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training tree 1 of 3 ------------------------------------------------------------\n",
      "\n",
      "---Training sub-tree of depth: 1 (180 instances)\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[  2  47  38 115 156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 116.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 900/900 [00:11<00:00, 75.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info gain: 0.3802\n",
      "Accuracy for binary dataset: 0.8556\n",
      "Number of SV: [34 31]\n",
      "----> Selected SVM info gain: 0.3802\n",
      "\n",
      "---Training sub-tree of depth: 2 (72 instances)\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[66 43 14 47 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 360/360 [00:11<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info gain: 0.0000\n",
      "Accuracy for binary dataset: 0.8194\n",
      "Number of SV: [19 13]\n",
      "Increase SVM_C...\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[34 51 50  8 62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 48.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 360/360 [00:11<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info gain: 0.1015\n",
      "Accuracy for binary dataset: 0.8611\n",
      "Number of SV: [14 12]\n",
      "----> Selected SVM info gain: 0.1015\n",
      "\n",
      "---Training sub-tree of depth: 3 (67 instances)\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[23 34 50 56 27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 119.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 335/335 [00:04<00:00, 81.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info gain: 0.1916\n",
      "Accuracy for binary dataset: 0.9104\n",
      "Number of SV: [8 7]\n",
      "----> Selected SVM info gain: 0.1916\n",
      "\n",
      "---Training sub-tree of depth: 4 (58 instances)\n",
      "\n",
      "---Training sub-tree of depth: 4 (9 instances)\n",
      "\n",
      "---Training sub-tree of depth: 3 (5 instances)\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[4 2 1 4 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 174.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 413.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info gain: 0.7219\n",
      "Accuracy for binary dataset: 0.0000\n",
      "Number of SV: [2 1]\n",
      "----> Selected SVM info gain: 0.7219\n",
      "\n",
      "---Training sub-tree of depth: 4 (4 instances)\n",
      "\n",
      "---Training sub-tree of depth: 4 (1 instances)\n",
      "\n",
      "---Training sub-tree of depth: 2 (108 instances)\n",
      "We use the Nyström Approximation WITHOUT Incomplete Cholesky Decomposition\n",
      "[92 91 66 91  8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 66.35it/s]\n",
      " 16%|█████████████████████████▎                                                                                                                                         | 84/540 [00:02<00:13, 34.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqrf_reproduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mpartition_sample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/quantum_random_forest.py:152\u001b[0m, in \u001b[0;36mQuantumRandomForest.train\u001b[0;34m(self, data_df, epochs, partition_sample_size, pca_dim, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     kern_el_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[43mqdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/quantum_decision_tree.py:79\u001b[0m, in \u001b[0;36mQuantumDecisionTree.train\u001b[0;34m(self, data_df, criterion, return_qdt, kern_el_dict)\u001b[0m\n\u001b[1;32m     76\u001b[0m     svm_num_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;28;01mif\u001b[39;00m svm_num_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;241m<\u001b[39m svm_num_train \u001b[38;5;28;01melse\u001b[39;00m svm_num_train \u001b[38;5;66;03m# Accounts for RP \u001b[39;00m\n\u001b[1;32m     77\u001b[0m     split_df_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_fn\u001b[38;5;241m.\u001b[39mtrain(data_df\u001b[38;5;241m=\u001b[39mdata_df, split_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_type, num_rand_gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rand_gen,\n\u001b[1;32m     78\u001b[0m                                         ret_split_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, svm_num_train\u001b[38;5;241m=\u001b[39msvm_num_train, kern_el_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkern_el_dict)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_and_train_child(split_df) \u001b[38;5;28;01mfor\u001b[39;00m split_df \u001b[38;5;129;01min\u001b[39;00m split_df_list]\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_num, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in splitting children. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ImpossibleSVMTrainError:\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/quantum_decision_tree.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     svm_num_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;28;01mif\u001b[39;00m svm_num_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;241m<\u001b[39m svm_num_train \u001b[38;5;28;01melse\u001b[39;00m svm_num_train \u001b[38;5;66;03m# Accounts for RP \u001b[39;00m\n\u001b[1;32m     77\u001b[0m     split_df_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_fn\u001b[38;5;241m.\u001b[39mtrain(data_df\u001b[38;5;241m=\u001b[39mdata_df, split_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_type, num_rand_gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_rand_gen,\n\u001b[1;32m     78\u001b[0m                                         ret_split_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, svm_num_train\u001b[38;5;241m=\u001b[39msvm_num_train, kern_el_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkern_el_dict)\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_and_train_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_df\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m split_df \u001b[38;5;129;01min\u001b[39;00m split_df_list]\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_num, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in splitting children. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ImpossibleSVMTrainError:\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/quantum_decision_tree.py:96\u001b[0m, in \u001b[0;36mQuantumDecisionTree._init_and_train_child\u001b[0;34m(self, data_df)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_and_train_child\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_df):\n\u001b[1;32m     95\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_child()\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m child\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/quantum_decision_tree.py:77\u001b[0m, in \u001b[0;36mQuantumDecisionTree.train\u001b[0;34m(self, data_df, criterion, return_qdt, kern_el_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m svm_num_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msvm_num_train[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]      \u001b[38;5;66;03m# Note depth starts at 1 while index starts at 0\u001b[39;00m\n\u001b[1;32m     76\u001b[0m svm_num_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;28;01mif\u001b[39;00m svm_num_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_df) \u001b[38;5;241m<\u001b[39m svm_num_train \u001b[38;5;28;01melse\u001b[39;00m svm_num_train \u001b[38;5;66;03m# Accounts for RP \u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m split_df_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rand_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rand_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mret_split_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm_num_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_num_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_and_train_child(split_df) \u001b[38;5;28;01mfor\u001b[39;00m split_df \u001b[38;5;129;01min\u001b[39;00m split_df_list]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_dts) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_num, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in splitting children. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/split_function.py:108\u001b[0m, in \u001b[0;36mSplitFunction.train\u001b[0;34m(self, data_df, split_type, num_rand_gen, ret_split_list, svm_num_train, kern_el_dict)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpqc, childindxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_best_pqc(pqc_list\u001b[38;5;241m=\u001b[39mrandom_pqcs, data_df\u001b[38;5;241m=\u001b[39mdata_df)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m split_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqke\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m     childindxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_best_svm_pqc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_num_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rand_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rand_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mpqc_arch_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbranch_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed valid split_type.\u001b[39m\u001b[38;5;124m\"\u001b[39m); exit()\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/split_function.py:222\u001b[0m, in \u001b[0;36mSplitFunction.select_best_svm_pqc\u001b[0;34m(self, data_df, num_train, num_rand_gen, pqc_arch_type, kern_el_dict)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnystrom:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_nystrom_transform()\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_svm_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m indxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(data_df\u001b[38;5;241m.\u001b[39mX, kern_el_dict\u001b[38;5;241m=\u001b[39mkern_el_dict)\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# print(indxs)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# print(list(data_df.y))\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/split_function.py:257\u001b[0m, in \u001b[0;36mSplitFunction._svm_train\u001b[0;34m(self, data_df, num_train, kern_el_dict)\u001b[0m\n\u001b[1;32m    255\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(data_df\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mvalues)) \n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# Randomly chooses landmark points and constructs the Nystrom embedding.\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeat_map_nystrom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_best_base_class_and_train(X, data_df)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/nystrom.py:56\u001b[0m, in \u001b[0;36mfit_transform\u001b[0;34m(self, X, kern_el_dict, gram_matrix)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, kern_el_dict\u001b[38;5;241m=\u001b[39mkern_el_dict, gram_matrix\u001b[38;5;241m=\u001b[39mgram_matrix)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(X, kern_el_dict\u001b[38;5;241m=\u001b[39mkern_el_dict, gram_matrix\u001b[38;5;241m=\u001b[39mgram_matrix)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prev_transform\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/nystrom.py:48\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(self, X, kern_el_dict, gram_matrix)\u001b[0m\n\u001b[1;32m     46\u001b[0m if gram_matrix is None:\n\u001b[1;32m     47\u001b[0m     embedded = self.kernel(X, self.basis_, kern_el_dict=kern_el_dict)\n\u001b[0;32m---> 48\u001b[0m else:\n\u001b[1;32m     49\u001b[0m     embedded = gram_matrix[:,self.basis_indxs_]\n\u001b[1;32m     51\u001b[0m return np.dot(embedded, self.normalization_.T)\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/split_function.py:130\u001b[0m, in \u001b[0;36mSplitFunction.kernel\u001b[0;34m(self, X1, X2, parallel, kern_el_dict)\u001b[0m\n\u001b[1;32m    128\u001b[0m     pqc_out \u001b[38;5;241m=\u001b[39m _parallel_compute_kernel(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpqc, cores\u001b[38;5;241m=\u001b[39mparallel, kern_el_dict\u001b[38;5;241m=\u001b[39mkern_el_dict)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     pqc_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpqc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mret_prob_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m K \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pqc_out)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(X1), \u001b[38;5;28mlen\u001b[39m(X2)))\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_svm_sym:\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/pqc.py:58\u001b[0m, in \u001b[0;36mPQC.__call__\u001b[0;34m(self, states, ret_prob_0, kern_el_dict)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, states, ret_prob_0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, kern_el_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124;03m\"\"\" This method runs the PQC and returns a real number for each state in the list of states. If ret_prob_0=True,\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        then the probability of the all 0 measurement is returned - for QKE. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     counts_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkern_el_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkern_el_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret_prob_0:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m prob_0_from_counts_list(counts_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpqc_sample_num)\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/pqc.py:107\u001b[0m, in \u001b[0;36mPQC.get_counts\u001b[0;34m(self, states, kern_el_dict)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_qubits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe given state must be of correct dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mrun(run_circ, initial_state\u001b[38;5;241m=\u001b[39mstate)\n\u001b[0;32m--> 107\u001b[0m counts_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_counts_from_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_q_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserved_q_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kern_el_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mdev_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcirq\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    110\u001b[0m     kern_el_dict\u001b[38;5;241m.\u001b[39madd_counts(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed, state, counts_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Studium/Module/7. Semester/Quantum Machine Learning/Final/QRF/Code/device.py:69\u001b[0m, in \u001b[0;36mQDevice.get_counts_from_results\u001b[0;34m(self, results, observed_q_label, seed)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeas_indicies \u001b[38;5;241m=\u001b[39m  [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(results\u001b[38;5;241m.\u001b[39mstate_vector())) \u001b[38;5;28;01mif\u001b[39;00m check_meas_q_indx_0(i, observed_q_label)]\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m exact_prob_0(results\u001b[38;5;241m.\u001b[39mstate_vector(), observed_q_label, indicies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeas_indicies)\n\u001b[0;32m---> 69\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mcirq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_state_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved_q_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mrepetitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counts_from_samples(samples) \n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mibm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qml/lib/python3.10/site-packages/cirq/sim/state_vector.py:227\u001b[0m, in \u001b[0;36msample_state_vector\u001b[0;34m(state_vector, indices, qid_shape, repetitions, seed)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Convert to individual qudit measurements.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m meas_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(shape[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices)\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbig_endian_int_to_digits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeas_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "qrf_reproduction.train(training_set, \n",
    "          partition_sample_size=180)               # Partition size is the number of instances given to each tree. Set to None to use all the data for all trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410fc17",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, preds_qrf = qrf_reproduction.test(testing_set, \n",
    "                          ret_pred=True, \n",
    "                          parallel=False,            # Set to False if you don't want parallel computation. Needs to be False for calc_tree_corr to be True.\n",
    "                          calc_tree_corr=True)       # True is required to later look at correlations between trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ff952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(f\"Classification report for QRF:\\n\"\n",
    "      f\"{metrics.classification_report(testing_set.y, preds_qrf)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91af29",
   "metadata": {},
   "source": [
    "#### Further analysis of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3856de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out tree\n",
    "qrf.print_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb823bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = qrf.compute_tree_correlation()\n",
    "for k,v in corr_dict.items():\n",
    "    print(\"Class\", k)\n",
    "    plt.imshow(v)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d2add",
   "metadata": {},
   "source": [
    "## Own implementation: Comparing Cholesky to non-cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a0469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "num_classes = 2\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, testing_set = data_preprocessing(X, y, \n",
    "                                           train_prop=0.75,        # Proportion of dataset allocated for training\n",
    "                                           X_dim=6)                # Determine the required dimension of the dataset. None for default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3486512",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_var = 'eff_anz_pqc_arch'                   \n",
    "num_trees = 6                                      \n",
    "max_depth = 7\n",
    "embedding_type = 'as_params_all'            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholesky = True\n",
    "qrf = QuantumRandomForest(n_qubits, 'clas', num_trees, criterion, max_depth=max_depth, \n",
    "                      min_samples_split=min_samples_split, tree_split_num=split_num, num_rand_meas_q=num_rand_meas_q,\n",
    "                      ensemble_var=ensemble_var, dt_type=dt_type, num_classes=num_classes, ensemble_vote_type='ave',\n",
    "                      num_params_split=num_params_split, num_rand_gen=num_rand_gen, pqc_sample_num=pqc_sample_num,\n",
    "                      embed=embedding_type, branch_var=branch_var, svm_num_train=svm_num_train, svm_c=svm_c, \n",
    "                      nystrom_approx=True, device=device, cholesky=cholesky)\n",
    "qrf.train(training_set, partition_sample_size=180)\n",
    "acc, preds_qrf = qrf.test(testing_set, \n",
    "                      ret_pred=True, \n",
    "                      parallel=False,            # Set to False if you don't want parallel computation. Needs to be False for calc_tree_corr to be True.\n",
    "                      calc_tree_corr=True)       # True is required to later look at correlations between trees\n",
    "# Classification report\n",
    "classification_report = metrics.classification_report(testing_set.y, preds_qrf)\n",
    "print(f\"Classification report for QRF (With Cholesky Improvement):\\n\"\n",
    "      f\"{classification_report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60338da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholesky = False\n",
    "qrf = QuantumRandomForest(n_qubits, 'clas', num_trees, criterion, max_depth=max_depth, \n",
    "                      min_samples_split=min_samples_split, tree_split_num=split_num, num_rand_meas_q=num_rand_meas_q,\n",
    "                      ensemble_var=ensemble_var, dt_type=dt_type, num_classes=num_classes, ensemble_vote_type='ave',\n",
    "                      num_params_split=num_params_split, num_rand_gen=num_rand_gen, pqc_sample_num=pqc_sample_num,\n",
    "                      embed=embedding_type, branch_var=branch_var, svm_num_train=svm_num_train, svm_c=svm_c, \n",
    "                      nystrom_approx=True, device=device, cholesky=cholesky)\n",
    "qrf.train(training_set, partition_sample_size=180)\n",
    "acc, preds_qrf = qrf.test(testing_set, \n",
    "                      ret_pred=True, \n",
    "                      parallel=False,            # Set to False if you don't want parallel computation. Needs to be False for calc_tree_corr to be True.\n",
    "                      calc_tree_corr=True)       # True is required to later look at correlations between trees\n",
    "# Classification report\n",
    "classification_report = metrics.classification_report(testing_set.y, preds_qrf)\n",
    "print(f\"Classification report for QRF (No Cholesky Improvement):\\n\"\n",
    "      f\"{classification_report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7560c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
